{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PfnqVYOuZbsP",
        "gBHVRErubpC7",
        "5S-PZ32xdibW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinajahangir/Cload-Data-Retrieval/blob/main/DaymetRetrieval_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First version: July 2025\n",
        "Sina Jahangir\n",
        "\n",
        "Downloads and processes Daymet v4 (Thornton et al., 2022) data using Google Earth Engine (GEE) API.\n",
        "\n",
        "Extracts time-series data for points (x,y) and shapefiles efficiently\n",
        "\n",
        "Saves results to a Pandas DataFrame for analysis or plotting\n",
        "\n",
        "Reference:\n",
        "Thornton, M.M., R. Shrestha, Y. Wei, P.E. Thornton, S-C. Kao, and B.E. Wilson. 2022. Daymet: Daily Surface Weather Data on a 1-km Grid for North America, Version 4 R1. ORNL DAAC, Oak Ridge, Tennessee, USA. https://doi.org/10.3334/ORNLDAAC/2129\n",
        "\n",
        "Key Features:\n",
        "\n",
        "✅ Custom data pre-process (feature selection)\n",
        "\n",
        "✅ Modular fraemwrok for efficiency and reproducibility\n",
        "\n",
        "✅ GEE utilization through Google Cloud\n",
        "\n",
        "MIT License\n",
        "Copyright (c) [2025] [Sina Jahangir]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ],
      "metadata": {
        "id": "_FBqdK9wBaLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "PfnqVYOuZbsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install earthengine-api # library used to access ee\n",
        "# Library import\n",
        "import ee\n",
        "import pandas as pd\n",
        "import os\n",
        "import geopandas as gpd\n",
        "import json"
      ],
      "metadata": {
        "id": "JoCSS328YcL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8851249b-3f8c-4bd7-962c-33bfd84d4fac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.11/dist-packages (1.5.22)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.19.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.175.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (0.2.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (0.22.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.32.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (4.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1dev,>=0.9.2->earthengine-api) (3.2.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (2025.6.15)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access GEE"
      ],
      "metadata": {
        "id": "gBHVRErubpC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "## Google Authentication\n",
        "ee.Authenticate()  # Authenticate with your Google account\n",
        "## Google Earth's API\n",
        "# Initialize the library\n",
        "#change based on your defined project on Google cloud\n",
        "ee.Initialize(project='...')\n",
        "\n",
        "print(ee.String('Hello from the Earth Engine servers!').getInfo())\n",
        "## Access Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV5HkP1diRws",
        "outputId": "83d32ec2-4780-4898-d628-547091a7d048"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from the Earth Engine servers!\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set settings"
      ],
      "metadata": {
        "id": "5S-PZ32xdibW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change directory to where Shapefiles are saved\n",
        "# This is for data retrieval based on shapefile\n",
        "os.chdir('/content/drive/MyDrive/PHIMP-Flood') #change this"
      ],
      "metadata": {
        "id": "axm3ejCS7l_t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define list of shapefiles\n",
        "shapefiles=['CanHydroFabric_Watersheds.shp']"
      ],
      "metadata": {
        "id": "8mKMnjB6FDz5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the directory exists before creating it to save the results\n",
        "'''\n",
        "Unfortunately, Google Earth Engine (GEE) Export.table.toDrive does (see below) not support subfolder paths\n",
        "(like 'parent/child') in the folder parameter.\n",
        "The folder must be a top-level folder in your Google Drive (My Drive),\n",
        "and it will not create nested folders.\n",
        "'''\n",
        "savefolder_name='DaymetExtraction'\n",
        "if not os.path.exists('/content/drive/MyDrive/%s'%(savefolder_name)):\n",
        "    os.mkdir('/content/drive/MyDrive/%s'%(savefolder_name))\n",
        "else:\n",
        "    print(\"Directory already exists.\")"
      ],
      "metadata": {
        "id": "uUJq10b9eFjn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data retrieval functions"
      ],
      "metadata": {
        "id": "txuV2ipweMms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zGnIOufmW9gt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "32b19869-0dec-4aac-d073-4a737ce9e550"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_dataset_for_point(lat, lon, start_date=\\'1980-01-01\\', end_date=\\'2023-12-31\\'):\\n    \"\"\"Retrieve and filter the DayMet dataset for a specific time range and location.\"\"\"\\n\\n    # Load the DayMet dataset and filter by date\\n    dataset = ee.ImageCollection(\\'NASA/ORNL/DAYMET_V4\\')\\n    dataset = dataset.filter(ee.Filter.date(start_date, end_date))\\n\\n    # Select all relevant variables\\n    variables = [\\'tmax\\', \\'tmin\\', \\'prcp\\', \\'srad\\', \\'vp\\']\\n    dataset = dataset.select(variables)\\n\\n    # Define the point of interest\\n    point = ee.Geometry.Point(lon, lat)\\n\\n    # Extract data for the given location\\n    data = dataset.getRegion(point, scale=1000).getInfo()\\n\\n    return data\\n  \\ndef convert_to_dataframe(data):\\n    \"\"\"Convert the extracted data to a Pandas DataFrame.\"\"\"\\n    if not data or len(data) < 2:\\n        return pd.DataFrame()\\n\\n    columns = data[0]  # First row contains column names\\n    values = data[1:]  # Remaining rows contain data\\n    df = pd.DataFrame(values, columns=columns)\\n    return df\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def get_dataset_for_shapefile(shapefile, start_date='1980-01-01',\\\n",
        "              end_date='2023-12-31',export_name='daymet_export'):\n",
        "    \"\"\"Retrieve and filter the DayMet dataset for a specific time range and spatially average over a shapefile.\"\"\"\n",
        "    # Initialize Earth Engine\n",
        "\n",
        "    # Load the DayMet dataset and filter by date\n",
        "    dataset = ee.ImageCollection('NASA/ORNL/DAYMET_V4')\n",
        "    dataset = dataset.filter(ee.Filter.date(start_date, end_date))\n",
        "\n",
        "    # Select all relevant variables\n",
        "    variables = ['prcp','srad','tmax', 'tmin','vp']\n",
        "    dataset = dataset.select(variables)\n",
        "\n",
        "    # Read the shapefile and convert to GeoJSON (ensure it's in lat/lon)\n",
        "    gdf = gpd.read_file(shapefile).to_crs(epsg=4326)\n",
        "    geojson_dict = json.loads(gdf.to_json())\n",
        "\n",
        "    # Convert to Earth Engine FeatureCollection\n",
        "    region = ee.FeatureCollection(geojson_dict)\n",
        "\n",
        "    def reduce_image(image):\n",
        "        mean_dict = image.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=region.geometry(),\n",
        "            scale=1000,\n",
        "            maxPixels=1e13\n",
        "        )\n",
        "        return ee.Feature(None, mean_dict).set('date', image.date().format('YYYY-MM-dd'))\n",
        "\n",
        "    reduced = dataset.map(reduce_image)\n",
        "\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        collection=reduced,\n",
        "        description=export_name,\n",
        "        fileFormat='CSV',\n",
        "        folder=savefolder_name,\n",
        "        fileNamePrefix=export_name,\n",
        "        selectors=['date']+ variables\n",
        "    )\n",
        "    task.start()\n",
        "    print(f'Export started: {export_name}. Check Google Drive.')\n",
        "# Point extraction (excluded for now)\n",
        "'''\n",
        "def get_dataset_for_point(lat, lon, start_date='1980-01-01', end_date='2023-12-31'):\n",
        "    \"\"\"Retrieve and filter the DayMet dataset for a specific time range and location.\"\"\"\n",
        "\n",
        "    # Load the DayMet dataset and filter by date\n",
        "    dataset = ee.ImageCollection('NASA/ORNL/DAYMET_V4')\n",
        "    dataset = dataset.filter(ee.Filter.date(start_date, end_date))\n",
        "\n",
        "    # Select all relevant variables\n",
        "    variables = ['tmax', 'tmin', 'prcp', 'srad', 'vp']\n",
        "    dataset = dataset.select(variables)\n",
        "\n",
        "    # Define the point of interest\n",
        "    point = ee.Geometry.Point(lon, lat)\n",
        "\n",
        "    # Extract data for the given location\n",
        "    data = dataset.getRegion(point, scale=1000).getInfo()\n",
        "\n",
        "    return data\n",
        "\n",
        "def convert_to_dataframe(data):\n",
        "    \"\"\"Convert the extracted data to a Pandas DataFrame.\"\"\"\n",
        "    if not data or len(data) < 2:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    columns = data[0]  # First row contains column names\n",
        "    values = data[1:]  # Remaining rows contain data\n",
        "    df = pd.DataFrame(values, columns=columns)\n",
        "    return df\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract and save the data as CSV file(s)"
      ],
      "metadata": {
        "id": "z63YjunnhOAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_name='02GA014' #change this\n",
        "# looping through the shapefiles\n",
        "for ii in range(len(shapefiles)):\n",
        "    get_dataset_for_shapefile(shapefiles[ii],export_name=export_name)\n",
        "'''\n",
        "This might take some time to complete.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUiYr_5oFYlq",
        "outputId": "15a174df-1f22-4c30-ab77-8a3e087310ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export started: 02GA014. Check Google Drive.\n"
          ]
        }
      ]
    }
  ]
}
